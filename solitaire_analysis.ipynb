{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><b><span style=\"color:lightseagreen\">Winning Deck: </span></b>Analysis with Tensorflow and AdaBoostRegressor - Brian Markley</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Winning Solitaire Decks with Tensorflow and AdaBoostRegressor.\n",
    "\n",
    "Given that some shuffled decks will win and some will lose in a game of solitaire (aka Klondike), can we generalize features of WINNING DECKS and predict if a newly shuffled deck will win? **OR**, are there so many possible winning decks and move-orders that patterns in the winning training decks could never generalize to unseen decks?\n",
    "\n",
    "## Process: \n",
    "I created a [Solitaire class in python][2] to play 10,000 games of solitaire and produce training data with a **card ID** (1-52) for each of the 52 locations in a shuffled deck (e.g. x0 = top card, x51 = bottom card), a **won** flag (true|false), and the **num_moves** (1-156) played until the deck was either won or lost. I produced an alternate data set where the 52 card features represented specific cards (e.g. x0 = 2-of-Spades, x51 = Ace-of-Hearts, with cell values giving the shuffled deck locations), but this yielded very similar results.\n",
    "\n",
    "Below, after basic exploration, I trained a classifier to target the **won** column and a regressor to target the correlated **num_moves** column using various column subsets, data transformations, and new statistical features. Although I am new to deep models, I thought it would be best to try one here since I'd expect any function to be very non-linear.\n",
    "\n",
    "## Conclusions:\n",
    "\n",
    "I found no way to identify winning decks. Although a trained tensorflow classifier could fully memorize the 7500 training decks and correctly classify 100% of samples pulled from within, it could not generalize to new decks. As a final gut-check, I added in a noise-degraded copy of the **num_moves** feature to the training data and showed 99% accuracy in classification.\n",
    "\n",
    "It appears winning decks use a sufficiently complex series of moves (usually more than 115) such that their initial states are indistinguishable from those of losing decks.\n",
    "This agrees with my experience that the difference between winning and losing often hinges on a single linchpin card appearing at the right time or failing to appear. A winning deck would appear statistically identical to one where only that linchpin card is offset by 1. \n",
    "\n",
    "## Ways to improve this?:\n",
    "\n",
    "I would love to hear thoughts on whether successful prediction sounds possible, and how I might improve. \n",
    "\n",
    "Some problems I see are:\n",
    "* My Solitaire playing algorithm only achieves ~18% success but research shows I should be able to achieve [~43%][1]. If I improve the algorithm, perhaps the wider pool of winnable decks might be more generalizable? Alternatively, since I'm already winning the 'easiest' decks, I might expect this could actually hurt generalizability, since it would add more marginal decks that take more complex game play to win.\n",
    "* I am new to deep models and am using a simple input layer. Perhaps this problem would lend itself to a differently shaped input layer representing card value, suit, and location for each card, and convolutional filters akin to vision problems?\n",
    "\n",
    "[1]: http://www.jupiterscientific.org/sciinfo/KlondikeSolitaireReport.html\n",
    "[2]: https://github.com/countingpigeons/winningdeck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Import](#1.-Import)\n",
    "    - 1.1 [libraries](#1.1-Libraries)\n",
    "    - 1.2 [data](#1.2-Data)\n",
    "    - 1.3 [clean and transform](#1.3-Clean,-Transform)\n",
    "    - 1.4 [summarize](#1.4-High-Level-Summary)\n",
    "\n",
    "***\n",
    "\n",
    "2. [Define Utility Functions](#2.-Define-Utility-Functions)\n",
    "    - 2.1 [prep input arrays with dummies](#2.1-Prep-input-arrays)\n",
    "    - 2.2 [deep model](#2.2-Deep-model)\n",
    "    - 2.3 [regression](#2.3-Regression)\n",
    "    - 2.4 [chart statistics](#2.4-Chart-statistics)\n",
    "\n",
    "***\n",
    "    \n",
    "3. [Model: Raw Card Indexes (naiive)](#3.-Model:-Raw-Card-Indexes)\n",
    "    - 3.1 [add feature: filter to deck positions where avg card diverges in winning decks](#3.1-Add-feature:-deck-positions-where-avg-card-diverges-in-winning-decks)\n",
    "    - 3.2 [add feature: filter to deck positions which are initially exposed in game play](#3.2-Add-feature:-deck-positions-which-are-initially-exposed-in-game-play)\n",
    "    - 3.3 [visualize index differences between specific positions in the deck](#3.3-Visualize-index-differences-between-specific-positions-in-the-deck)\n",
    "    - 3.4 [create input arrays](#3.4-Create-input-arrays)\n",
    "    - 3.5 [run models](#3.5-Run-models)\n",
    "\n",
    "\n",
    "4. [Model: Summarize Important Initial Deck Positions](#4.-Model:-Summarize-Important-Deck-Positions)\n",
    "    - 4.1 [create features (#exposed aces, #pile top kings, #pile top blacks, and #pile top evens)](#4.1-Create-features)\n",
    "    - 4.2 [visualize](#4.2-Visualize)\n",
    "    - 4.3 [normalize](#4.3-Normalize)\n",
    "    - 4.4 [create input arrays](#4.4-Create-input-arrays)\n",
    "    - 4.5 [run models](#4.5-Run-models)\n",
    "\n",
    "\n",
    "5. [Model: Card Values and Suits](#5.-Model:-Card-Values-and-Suits)\n",
    "    - 5.1 [dictionaries for val and suit](#5.1-Dictionaries-for-val-and-suit)\n",
    "    - 5.2 [create new columns](#5.2-Create-new-columns)\n",
    "    - 5.3 [add feature: deck positions where avg card diverges in winning decks](#5.3-Add-feature:-deck-positions-where-avg-card-diverges-in-winning-decks)\n",
    "    - 5.4 [create input arrays](#5.4-Create-input-arrays)\n",
    "    - 5.5 [run models](#5.5-Run-models)\n",
    "\n",
    "\n",
    "6. [Model: Value offsets between deck positions](#6.-Model:-Value-offsets-between-deck-positions)\n",
    "    - 6.1 [visualize card values between pairs of positions.](#6.1-Visualize-card-values-between-pairs-of-positions.)\n",
    "    - 6.2 [create value offset features](#6.2-Create-value-offset-features)\n",
    "    - 6.3 [create filter to identify new features](#6.3-Create-filter-to-identify-new-features)\n",
    "    - 6.4 [create input arrays](#6.4-Create-input-arrays)\n",
    "    - 6.5 [run models](#6.5-Run-models)\n",
    "\n",
    "\n",
    "7. [Model: Deck Statistics](#7.-Model:-Deck-Statistics)\n",
    "    - 7.1 [add feature: number of contiguous values](#7.1-Add-feature:-number-of-contiguous-values)\n",
    "    - 7.2 [add feature: value balance between halves of the deck](#7.2-Add-feature:-value-balance-between-halves-of-the-deck)\n",
    "    - 7.3 [add feature: color balance between alternating cards](#7.3-Add-feature:-color-balance-between-alternating-cards)\n",
    "    - 7.4 [add feature: color balance between halves of the deck](#7.4-Add-feature:-color-balance-between-halves-of-the-deck)\n",
    "    - 7.5 [add feature: color balance from top to bottom continuously](#7.5-Add-feature:-color-balance-from-top-to-bottom-continuously)\n",
    "    - 7.6 [create filter for new features](#7.6-Create-filter-for-new-features)\n",
    "    - 7.7 [summarize and visualize](#7.7-Summarize-and-visualize)\n",
    "    - 7.8 [create input arrays](#7.8-Create-input-arrays)\n",
    "    - 7.9 [run models](#7.9-Run-models)\n",
    "\n",
    "\n",
    "8. [Model: Identify Quick Losers](#8.-Model:-Identify-Quick-Losers)\n",
    "    - 8.1 [find minimum move threshold for a 'fun' deck](#8.1-Find-minimum-move-threshold-for-a-'fun'-deck)\n",
    "    - 8.2 [create input arrays](#8.2-Create-input-arrays)\n",
    "    - 8.3 [run models](#8.3-Run-models)\n",
    "\n",
    "\n",
    "9. [Model: Gut Check](#9.-Model:-Gut-Check)\n",
    "    - 9.1 [degrade num_moves with random noise](#9.1-Degrade-num_moves-feature-with-random-noise)\n",
    "    - 9.2 [create input arrays (with noisy num_moves added)](#9.2-Create-input-arrays)\n",
    "    - 9.3 [run models](#9.3-Run-models)\n",
    "\n",
    "***\n",
    "    \n",
    "10. [Conclusions](#10.-Conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# sklearn tools\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# deep model\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'winning_deck_results')\n",
    "pd.DataFrame(data.dtypes).transpose()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Clean, Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform won/lost as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,'won'] = data.won.str.contains('True').replace({True:1,False:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### transform categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all \"x\" columns\n",
    "card_column_names = list(filter(lambda column: column[0:1]=='x', list(data.columns)))\n",
    "card_columns = data.columns.isin(card_column_names)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for column in card_column_names:\n",
    "        data.loc[:,column] = pd.Categorical(data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 High Level Summary\n",
    "    Approximately 19% are winning decks, and the \"num_moves\" field clearly distinguishes winners from losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=[16,3])\n",
    "\n",
    "_= sns.countplot(x='won', data=data, ax=axes[0], palette={0:'khaki',1:'blue'})\n",
    "_= sns.boxplot(x='won', y='num_moves', hue='won', data=data, ax=axes[1], palette={0:'khaki',1:'blue'}, width=1.6)\n",
    "_=axes[0].set_title('Won/Lost (count)')\n",
    "_=axes[1].set_title('Won/Lost (num_moves)')\n",
    "_=axes[1].set_xlim(-1,2)\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = data.groupby('won')['num_moves'].agg([len,min, max, np.mean]).\\\n",
    "    rename(columns={'len':'Num','min':'MinMoves','max':'MaxMoves', 'mean':'MeanMoves'})\n",
    "details.MeanMoves = details.MeanMoves.transform(int)\n",
    "details['Ratio'] = details.Num.transform(lambda x:x/len(data))\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Prep input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pct = 0.75\n",
    "data_rows = data.shape[0]\n",
    "train_rows = int(np.ceil(data_rows * train_pct))\n",
    "training_index = data.sample(train_rows, random_state=0).index\n",
    "\n",
    "def split_train_test(df):\n",
    "    train = df.loc[training_index]\n",
    "    test = df.loc[~df.index.isin(training_index)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_with_dummies(df, columns):\n",
    "    array = np.array(pd.get_dummies(df.loc[:, columns], drop_first=True, sparse=True))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_deep_model(training_array):\n",
    "    num_input_features = training_array[0].size\n",
    "    num_hidden_neurons = min(num_input_features//2, 13)\n",
    "\n",
    "    deep_model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(num_input_features, activation='relu'),\n",
    "      tf.keras.layers.Dense(num_hidden_neurons, activation='sigmoid'),\n",
    "      tf.keras.layers.Dense(3),\n",
    "      tf.keras.layers.Dropout(rate=0.2, seed=0),\n",
    "      tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    deep_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return deep_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_predictions(model, test_array, fitted_model):\n",
    "\n",
    "    probas = model.predict_proba(test_array)[:,1]\n",
    "    num_moves = y_test_regress\n",
    "    won = y_test\n",
    "    if str(model.name)[:10] == 'sequential':\n",
    "        model_name = 'Deep Model'\n",
    "    else: model_name = 'Sklearn Model'\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=[16, 4])    \n",
    "    _=fig.suptitle('{} (inputs: {})'.format(model_name, str(test_array.shape[1])), fontsize=12)\n",
    "    _=axes[0].plot(fitted_model.history['acc'], label='train', color='royalblue', linewidth=2, marker='o')\n",
    "    _=axes[0].plot(fitted_model.history['val_acc'], label='validate', color='gray', linewidth=2, marker='o')\n",
    "    _=axes[0].set_xlabel('Training Epoch')\n",
    "    _=axes[0].set_ylabel('Accuracy (ratio)')\n",
    "    _=axes[0].set_title('Training')\n",
    "    _=axes[0].legend()\n",
    "    _=axes[0].set_xticks([0,1,2,3,4])\n",
    "    _=axes[0].set_xticklabels(['1','2','3','4','5'])\n",
    "    _=axes[0].set_ylim([.6,1.05])\n",
    "\n",
    "    _=axes[1].scatter(probas, num_moves, c=won, s=1, cmap='coolwarm_r', label='blue:won, red:lost')\n",
    "    _=axes[1].set_xlabel('Probability Won (predicted)')\n",
    "    _=axes[1].set_ylabel('Num Moves (actual)')\n",
    "    _=axes[1].set_title('Test Predictions')\n",
    "    _=axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model_and_chart(train_x, train_y, test_x, test_y, baseline=0):\n",
    "    deep_model = make_deep_model(train_x)\n",
    "    fitted_model=deep_model.fit(train_x, train_y, epochs=5, verbose=0, validation_split=.10)\n",
    "    \n",
    "    model_accuracy = deep_model.evaluate(test_x, test_y, verbose=0)[1]\n",
    "    baseline = max(baseline, len(test.loc[test.won==0]) / len(test))  #ratio of LOST in test set\n",
    "\n",
    "    print('Accuracy: {:.4f}'.format(model_accuracy))\n",
    "    print('     vs. baseline: {:.4f}'.format(model_accuracy - baseline))\n",
    "    chart_predictions(deep_model, test_x, fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboostregressor = AdaBoostRegressor(random_state = 0,loss='linear')\n",
    "\n",
    "def chart_regression(model, test_array):\n",
    "    predicted_moves = model.predict(test_array)\n",
    "    num_moves = y_test_regress\n",
    "    won = y_test\n",
    "    model_name = adaboostregressor.__str__()\n",
    "    model_name = model_name[:model_name.index('(')]\n",
    "    _=plt.scatter(predicted_moves, num_moves, c=won, s=1, cmap='coolwarm_r')\n",
    "    _=plt.xlabel('Num Moves (predicted)')\n",
    "    _=plt.ylabel('Num Moves (actual)')\n",
    "    _=plt.xlim(0, 160)\n",
    "    _=plt.ylim(0, 160)\n",
    "    _=plt.title('{} (inputs: {})'.format(model_name, str(test_array.shape[1])))\n",
    "\n",
    "def regress_and_chart(train_x, train_y, test_x, test_y):\n",
    "    _=adaboostregressor.fit(train_x, train_y)\n",
    "    R2 = adaboostregressor.score(test_x, test_y)\n",
    "    \n",
    "    print('R^2: {}'.format(round(R2, 2)))\n",
    "    chart_regression(adaboostregressor, test_x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Chart statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_column_stats(column_name_str, title_str, xlabel_str):\n",
    "    won_mean = data.loc[data.won==1, column_name_str].mean()\n",
    "    won_std = data.loc[data.won==1, column_name_str].std()\n",
    "    lost_mean = data.loc[data.won==0, column_name_str].mean()\n",
    "    lost_std = data.loc[data.won==0, column_name_str].std()\n",
    "    ttest = ttest_ind(data.loc[data.won==1, column_name_str], data.loc[data.won==0, column_name_str])\n",
    "    ftest = (won_std ** 2) / (lost_std ** 2)\n",
    "    print('Mean Difference | p: {:.2f} | F: {:.3f}'.format(ttest[1], ftest))\n",
    "\n",
    "    diffs = data.loc[:, column_name_str]\n",
    "    num_moves = data.loc[:, 'num_moves']\n",
    "    won = data.loc[:, 'won']\n",
    "    plot=plt.scatter(diffs, num_moves, c=won, s=1, cmap='coolwarm_r', alpha=.5)\n",
    "    plot=plt.xlabel(xlabel_str)\n",
    "    plot=plt.ylabel('Num Moves (actual)')\n",
    "\n",
    "    plot=plt.axvline(x=lost_mean, color='red', linewidth=.8)\n",
    "    plot=plt.axvline(x=lost_mean-lost_std, color='red', linewidth=.8, linestyle='--')\n",
    "    plot=plt.axvline(x=lost_mean+lost_std, color='red', linewidth=.8, linestyle='--')\n",
    "\n",
    "    plot=plt.axvline(x=won_mean, color='blue', linewidth=.8)\n",
    "    plot=plt.axvline(x=won_mean-won_std, color='blue', linewidth=.8, linestyle='--')\n",
    "    plot=plt.axvline(x=won_mean+won_std, color='blue', linewidth=.8, linestyle='--')\n",
    "\n",
    "    plot=plt.title(title_str,fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model: Raw Card Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Add feature: deck positions where avg card diverges in winning decks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Average card index per deck position in winning and losing decks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=data.loc[:,card_columns].mean().plot(kind='bar',color='grey',figsize=[16,2], alpha=0.5, ylim=[24,28], label='avg')\n",
    "_=data.loc[data.won==1,card_columns].mean().plot(kind='bar',color='blue', alpha=0.9, label='won')\n",
    "_=data.loc[data.won==0,card_columns].mean().plot(kind='bar',color='yellow', alpha=0.5, label='lost')\n",
    "_=plt.legend(bbox_to_anchor=(1, .6))\n",
    "_=plt.axhline(y=26.5, color='r', linestyle='--', linewidth=0.7)\n",
    "_=plt.xlabel('Deck Position')\n",
    "_=plt.ylabel('Card Index (avg)')\n",
    "_=plt.title('Avg Card Index per Position (E(X)=26.5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create feature of deck positions where winning decks diverge from expected 26.5 (blue peaks above/below red line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergent_column_names = ['x7','x22','x25','x34','x41','x44','x48','x51']\n",
    "divergent_columns = data.columns.isin(divergent_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Add feature: deck positions which are initially exposed in game play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create feature of deck positions guaranteed to be exposed in every game (pile tops and initial every-third)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_exposed_column_names = ['x0','x7','x13','x18','x22','x25','x27']\n",
    "initial_playpile_column_names = ['x30','x33','x36','x39','x42','x45','x48','x51']\n",
    "\n",
    "filtered_column_names = initial_exposed_column_names.copy()\n",
    "filtered_column_names.extend(initial_playpile_column_names)\n",
    "filtered_columns = data.columns.isin(filtered_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Visualize index differences between specific positions in the deck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Do certain cards often appear at a given offset from each other in winning decks? (e.g. if the top card ('x0') is a red 3-of-hearts (index 28), is it common in winning decks for the 20th card ('x19') to be a black 4 (index 3 or 16)?) \n",
    "\n",
    "    I may expect to see diagonal lines where value/color combinations relate to other value/color combinations at specific depths from that card location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrows=9\n",
    "ax_row = 0\n",
    "ax_col = -1\n",
    "tickrange=[0,7,13,20,26,33,39,46]\n",
    "xticklabels=['2S','9S','2C','9C','2H','9H','2D','9D']\n",
    "yticklabels=['2-Spades','9-Spades','2-Clubs','9-Clubs','2-Hearts','9-Hearts','2-Diamonds','9-Diamonds']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=numrows, ncols=6, figsize=[24,4*numrows],sharey=True)\n",
    "_=fig.suptitle(t='FactoryDeck index per pair of deck positions (darker=more won)', fontsize=25, y=(1-(.011*numrows)))\n",
    "\n",
    "x = 'x0'\n",
    "for column in card_column_names[:]:\n",
    "    if int(column[1:]) == 0:\n",
    "        continue\n",
    "    y = column\n",
    "    \n",
    "    if ax_col == 5:\n",
    "        ax_row+=1\n",
    "        ax_col=0\n",
    "    else: \n",
    "        ax_col+=1        \n",
    "    ax = axes[ax_row][ax_col]\n",
    "\n",
    "    _=ax.scatter(x=data[x], y=data[y], c=data['won'], cmap='binary', s=10, alpha=.6)\n",
    "    _=ax.set_xticks(tickrange)\n",
    "    _=ax.set_xticklabels(xticklabels)\n",
    "    _=ax.set_yticks(tickrange)\n",
    "    _=ax.set_yticklabels(yticklabels)\n",
    "    _=ax.set_title(label='{} - {}'.format(x[1:], y[1:]), fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Initially plotting only the top card against the other 51 deck positions doesn't reveal a clear relationship. Not expanding to all pair-wise comparisons since spot checking those also doesn't reveal any patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Create input arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train/Test Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=[16,3],constrained_layout=True)\n",
    "\n",
    "_= sns.countplot(x='won', data=train, ax=axes[0], palette={0:'khaki',1:'blue'})\n",
    "_= sns.countplot(x='won', data=test, ax=axes[1], palette={0:'khaki',1:'blue'})\n",
    "_=axes[0].set_title('Train')\n",
    "_=axes[1].set_title('Test')\n",
    "\n",
    "train_win_ratio = train.won.mean()\n",
    "test_win_ratio = test.won.mean()\n",
    "\n",
    "print('TRAIN - Won: {}  Lost: {}'.format(train_win_ratio.round(4), (1-train_win_ratio).round(4)))\n",
    "print('TEST - Won: {}  Lost: {}'.format(test_win_ratio.round(4), (1-test_win_ratio).round(4)))\n",
    "print('Diff in win means: {}'.format(abs(train_win_ratio - test_win_ratio).round(4)))\n",
    "print('    p value that Diff is random: {}'.format(ttest_ind(train.won, test.won)[1].round(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=[16,3],constrained_layout=True)\n",
    "\n",
    "_= sns.boxplot(x='won', y='num_moves', hue='won', data=train, ax=axes[0], palette={0:'khaki',1:'blue'}, width=1.6)\n",
    "_= sns.boxplot(x='won', y='num_moves', hue='won', data=test, ax=axes[1], palette={0:'khaki',1:'blue'}, width=1.6)\n",
    "\n",
    "for ax in axes:\n",
    "    _=ax.set_xlim(-1,2)\n",
    "    _=ax.yaxis.grid(True)\n",
    "_=axes[0].set_title('Train')\n",
    "_=axes[1].set_title('Test')\n",
    "\n",
    "print('p value that num_moves Diff is random: {}'.format(ttest_ind(train.num_moves, test.num_moves)[1].round(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline (ratio LOST in the test set) = .8176.\n",
    "\n",
    "<b><span style=\"color:lightseagreen\">Split looks good.</span></b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = array_with_dummies(train, card_columns)\n",
    "X_train_filtered = array_with_dummies(train, filtered_columns)\n",
    "X_train_divergent = array_with_dummies(train, divergent_columns)\n",
    "\n",
    "y_train = np.array(train.loc[:,(train.columns=='won')].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = array_with_dummies(test, card_columns)\n",
    "X_test_filtered = array_with_dummies(test, filtered_columns)\n",
    "X_test_divergent = array_with_dummies(test, divergent_columns)\n",
    "\n",
    "y_test = np.array(test.loc[:,(test.columns=='won')].iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternate y for regression on 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_regress = np.array(train.loc[:,(train.columns=='num_moves')].iloc[:,0])\n",
    "y_test_regress = np.array(test.loc[:,(test.columns=='num_moves')].iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape\n",
    "X_train_filtered.shape, X_test_filtered.shape\n",
    "X_train_divergent.shape, X_test_divergent.shape\n",
    "\n",
    "y_train.shape, y_test.shape\n",
    "y_train_regress.shape, y_test_regress.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_filtered,y_train,X_test_filtered,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_divergent,y_train,X_test_divergent,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Center and distribution match between Won and Lost so no useful signal on these feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoostRegressor - 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train, y_train_regress, X_test, y_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_filtered, y_train_regress, X_test_filtered, y_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_divergent, y_train_regress, X_test_divergent, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Poor regression. R^2 very near 0, so explains little to none of variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal.</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model: Summarize Important Deck Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize among cards on top of the initial 7 piles, and those exposed in the 1st cycle through play deck.\n",
    "\n",
    "1. number of <b>aces</b> exposed (<i>perhaps high number is helpful, since all playable</i>)\n",
    "\n",
    "2. number of <b>kings</b> in pile tops (<i>perhaps high number hurtful, since can't play on other cards</i>)\n",
    "\n",
    "3. ratio of <b>red / black</b> cards in pile tops. (<i>Better if all one color, or balanced 50/50? If all same color, none can play on each other initially</i>)\n",
    "\n",
    "4. ratio of <b>even / odd</b> cards in pile tops. (<i>Better if all same, or if balanced? If all same, none can play on each other initially</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# card indexes corresponding to various categories.\n",
    "aces = [13, 26, 39, 52]\n",
    "kings = [12, 25, 38, 51]\n",
    "black = list(range(1,27))\n",
    "evens = [1,3,5,7,9,11,14,16,18,20,22,24,27,29,31,33,35,37,40,42,44,46,48,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'i_exposed_aces'] = data.loc[:, filtered_columns].\\\n",
    "            transform(lambda x: x.isin(aces)).replace({True:1, False:0}).sum(axis=1)\n",
    "data.loc[:, 'i_pile_kings'] =   data.loc[:, initial_exposed_column_names].\\\n",
    "            transform(lambda x: x.isin(kings)).replace({True:1, False:0}).sum(axis=1)\n",
    "data.loc[:, 'i_pile_blacks'] =  data.loc[:, initial_exposed_column_names].\\\n",
    "            transform(lambda x: x.isin(black)).replace({True:1, False:0}).sum(axis=1)\n",
    "data.loc[:, 'i_pile_evens'] =   data.loc[:, initial_exposed_column_names].\\\n",
    "            transform(lambda x: x.isin(evens)).replace({True:1, False:0}).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_card_column_names = list(filter(lambda x:x[0:2]=='i_', list(data.columns)))\n",
    "important_card_column_names\n",
    "important_card_columns = data.columns.isin(important_card_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = len(important_card_column_names)\n",
    "\n",
    "fig, axes = plt.subplots(1,num_plots,sharey=True,figsize=[16,4])\n",
    "ax = 0\n",
    "for column in important_card_column_names:\n",
    "    sns_plot = sns.countplot(x=column, hue='won', data=data, ax=axes[ax])\n",
    "    ax+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obvious win/lose ratio differences based on these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in important_card_column_names:\n",
    "    mean = data[column].mean()\n",
    "    std = data[column].std()\n",
    "    data.loc[:, column] = data.loc[:,column].transform(lambda x: (x-mean)/std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Create input arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_important_column_features = np.array(train.loc[:, important_card_columns])\n",
    "X_test_important_column_features = np.array(test.loc[:, important_card_columns])\n",
    "\n",
    "X_train_important_column_features.shape, X_test_important_column_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = preprocessing.PolynomialFeatures(degree=4, interaction_only=True)\n",
    "X_train_poly_important_column_features = poly.fit_transform(X_train_important_column_features, y_train)\n",
    "X_test_poly_important_column_features = poly.fit_transform(X_test_important_column_features, y_test)\n",
    "\n",
    "X_train_poly_important_column_features.shape, X_test_poly_important_column_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_important_column_features, y_train, X_test_important_column_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_poly_important_column_features, y_train, X_test_poly_important_column_features, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor on 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_important_column_features, y_train_regress,\\\n",
    "                  X_test_important_column_features, y_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_poly_important_column_features, y_train_regress,\\\n",
    "                  X_test_poly_important_column_features, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal.</span></b>\n",
    "Still predicting LOSE for all decks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model: Card Values and Suits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>RE-CODE</b> the input data to reflect card <b>VALUES</b> and <b>SUITS</b> instead of indexes in a factory deck.\n",
    "  \n",
    "1. create 52 <b>card value</b> columns with values (1-13).\n",
    "2. create 52 <b>card suit</b> columns with values (1-4). e.g. (\"x0_val\" [1-13], \"x0_suit\" [1-4], \"X1_val\" ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Dictionaries for val and suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our factory deck order is Two through Ace repeated 4 times.\n",
    "card_values = list(range(2,14))\n",
    "card_values.append(1)\n",
    "card_values = card_values * 4\n",
    "\n",
    "# our factory deck order is Spades, Clubs, Hearts, Diamonds, 13 each.\n",
    "card_suits = ([1]*13) + ([2]*13) + ([3]*13) + ([4]*13)\n",
    "\n",
    "\n",
    "card_indexes = range(1,53)\n",
    "\n",
    "# dictionaries\n",
    "cardval_dict = dict(zip(card_indexes,card_values))\n",
    "cardsuit_dict = dict(zip(card_indexes,card_suits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = list(filter(lambda x:x[0:1]=='x', list(data.columns)))\n",
    "for col in x_columns:\n",
    "    newcol = 'val_'+ col[1:]\n",
    "    data.loc[:, newcol] = pd.Categorical(data.loc[:, col].transform(lambda x:cardval_dict[x]))\n",
    "\n",
    "value_column_names = list(filter(lambda x:x[0:4]=='val_', list(data.columns)))\n",
    "print('sample of new value_columns: {}'.format(value_column_names[0:5]))\n",
    "value_columns = data.columns.isin(value_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in x_columns:\n",
    "    newcol = 'suit_'+ col[1:]\n",
    "    data.loc[:, newcol] = pd.Categorical(data.loc[:, col].transform(lambda x:cardsuit_dict[x]))\n",
    "\n",
    "suit_column_names = list(filter(lambda x:x[0:5]=='suit_', list(data.columns)))\n",
    "print('sample of new suit_columns: {}'.format(suit_column_names[0:5]))\n",
    "suit_columns = data.columns.isin(suit_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_and_suit_column_names = []\n",
    "value_and_suit_column_names.extend(value_column_names)\n",
    "value_and_suit_column_names.extend(suit_column_names)\n",
    "\n",
    "value_and_suit_columns = data.columns.isin(value_and_suit_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Add feature: deck positions where avg card diverges in winning decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=data.loc[:,value_columns].mean().plot(kind='bar',color='grey',figsize=[16,2], alpha=0.5, ylim=[5,8], label='avg')\n",
    "_=data.loc[data.won==1,value_columns].mean().plot(kind='bar',color='blue', alpha=0.9, label='won')\n",
    "_=data.loc[data.won==0,value_columns].mean().plot(kind='bar',color='yellow', alpha=0.5, label='lost')\n",
    "_=plt.axhline(y=7, color='r', linestyle='--', linewidth=0.7)\n",
    "_=plt.legend(bbox_to_anchor=(1, .6))\n",
    "_=plt.xlabel('Deck Position')\n",
    "_=plt.ylabel('Card Value (avg)')\n",
    "_=plt.title('Avg Card Value per Position (E(X)=7)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### make new filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergent_value_column_names = ['val_3','val_4','val_6','val_24','val_25','val_27','val_28']\n",
    "divergent_suit_column_names = ['suit_3','suit_4','suit_6','suit_24','suit_25','suit_27','suit_28']\n",
    "divergent_value_and_suit_column_names = divergent_value_column_names.copy()\n",
    "divergent_value_and_suit_column_names.extend(divergent_suit_column_names)\n",
    "\n",
    "divergent_value_and_suit_columns = data.columns.isin(divergent_value_and_suit_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Create input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_recode = array_with_dummies(train, value_and_suit_columns)\n",
    "X_test_recode = array_with_dummies(test, value_and_suit_columns)\n",
    "X_train_recode.shape\n",
    "X_test_recode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_recode_divergent = array_with_dummies(train, divergent_value_and_suit_columns)\n",
    "X_test_recode_divergent = array_with_dummies(test, divergent_value_and_suit_columns)\n",
    "X_train_recode_divergent.shape\n",
    "X_test_recode_divergent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_recode, y_train, X_test_recode, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_recode_divergent, y_train, X_test_recode_divergent, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor on 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_recode, y_train_regress, X_test_recode, y_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_recode_divergent, y_train_regress, X_test_recode_divergent, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal.</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model: Value offsets between deck positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Visualize card values between pairs of positions.\n",
    "I may expect to see dark diagonal lines if certain values often appear a certain offset away in winning decks. I do <b>NOT</b> see this however, as this first set of charts appear pretty random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numrows=9\n",
    "ax_row = 0\n",
    "ax_col = -1\n",
    "tickrange=range(1,14)\n",
    "xticklabels=['A','','','','','','7','','','','','','K']\n",
    "yticklabels=['Ace','2','3','4','5','6','7','8','9','10','Jack','Queen','King']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=numrows, ncols=6, figsize=[24,4*numrows], sharey=True)\n",
    "_=fig.suptitle(t='Ace-to-King values per pair of deck positions (darker=more won)', fontsize=25, y=.905)\n",
    "\n",
    "x = 'val_0'\n",
    "for column in value_column_names:\n",
    "    if int(column[4:]) == 0:\n",
    "        continue\n",
    "    y = column\n",
    "    \n",
    "    if ax_col == 5:\n",
    "        ax_row+=1\n",
    "        ax_col=0\n",
    "    else: \n",
    "        ax_col+=1        \n",
    "    ax = axes[ax_row][ax_col]\n",
    "    \n",
    "    _=ax.scatter(x=data[x], y=data[y], c=data['won'], cmap='binary', s=80, alpha=.6)\n",
    "    _=ax.set_xticks(tickrange)\n",
    "    _=ax.set_xticklabels(xticklabels)\n",
    "    _=ax.set_yticks(tickrange)\n",
    "    _=ax.set_yticklabels(yticklabels)\n",
    "\n",
    "    _=ax.set_title(label='{} - {}'.format(x[4:], y[4:]), fontdict={'fontsize':20})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not expanding this beyond initial x0 card, as spot checking others also does not suggest obvious patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Create value offset features\n",
    "For each of the first 51 cards, build a new column storing its value difference from each subsequent card. ~~Normalize between [-1, 1] by dividing by 12.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in value_column_names[:51]:\n",
    "    this_col_num = int(col[4:])\n",
    "    for other in value_column_names[this_col_num+1:]:\n",
    "        other_col_num = int(other[4:])\n",
    "\n",
    "        new_col_name = 'val_diff_'+str(this_col_num)+'_'+str(other_col_num)\n",
    "        data.loc[:,new_col_name] = pd.Categorical(data.loc[:,col].astype('int') - data.loc[:,other].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Create filter to identify new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_diff_column_names = list(filter(lambda x: x[0:8]=='val_diff',list(data.columns)))\n",
    "val_diff_columns = data.columns.isin(val_diff_column_names)\n",
    "\n",
    "data.loc[:0,value_columns]\n",
    "data.loc[:0,val_diff_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Create input arrays\n",
    "Because of memory constraints on my hardware, I am using only a fraction of the 1,326 val_diff columns to create dummy variables and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)\n",
    "\n",
    "X_train_val_diffs = array_with_dummies(train, val_diff_columns[:len(val_diff_columns)//6])\n",
    "X_test_val_diffs = array_with_dummies(test, val_diff_columns[:len(val_diff_columns)//6])\n",
    "\n",
    "X_train_val_diffs.shape, X_test_val_diffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_val_diffs, y_train, X_test_val_diffs, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_val_diffs, y_train_regress, X_test_val_diffs, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style='color:indian red; font-size:14pt'>No Signal.</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model: Deck Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * <b>How common are contiguous card values?</b> \n",
    "          Sum number of contiguous values (next card value higher or lower by ONE) throughout deck.\n",
    "          ex. A perfectly contiguous deck might ensure dependent cards (contiguous ones) aren't far from each other.\n",
    "\n",
    "   * <b>How well are values balanced between the two halves of the deck?</b> \n",
    "          Sum card values for each half.\n",
    "          ex. If h1 low and h2 high, the low-value piles (mostly comprised of h1) might be tough targets for high-\n",
    "          value playing deck (mostly comprised of h2).\n",
    "\n",
    "   * <b>How is the color spread among alternating cards?</b> \n",
    "          Sum indexes for even and odd deck positions. The abs(difference) in these sums is maximized when the cards \n",
    "          perfectly alternate between red and black. Perhaps this alternation could discourage 'stuck' states where \n",
    "          all visible cards are the same color.\n",
    "\n",
    "   * <b>How is the color balanced between the two halves of the deck?</b> \n",
    "          Sum indexes for even and odd deck positions. Indexes 1-26 are black cards and 27-52 are red. If h1 \n",
    "          entirely black and h2 entirely red then perhaps the black piles would be easier targets for the red\n",
    "          playpile. Perhaps large difference between index-sums of the piles leads to easier targets.\n",
    "   * <b>How is the color balanced from top to bottom continuously?</b> \n",
    "          Collect a running sum of the index difference between each deck position to get a more precise \n",
    "          'fingerprint' of the index order of each deck. Since this method records the ordering within each deck \n",
    "          half as well, it may inform whether bunches of value differerences are helpful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Add feature: number of contiguous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 0\n",
    "first_value_column = value_column_names[0]\n",
    "\n",
    "for row in data.index:\n",
    "    num_rows += 1\n",
    "    num_contiguous_values = 0\n",
    "    current_value = 0\n",
    "    previous_value = 0\n",
    "    for column in value_column_names:\n",
    "        current_value = data.loc[row, column]\n",
    "        if ((column != first_value_column) & (abs(current_value - previous_value)==1)):\n",
    "            num_contiguous_values += 1\n",
    "        previous_value = current_value\n",
    "    data.loc[row, 'z_num_contiguous_values'] = num_contiguous_values\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_mean = data.loc[:, 'z_num_contiguous_values'].mean()\n",
    "contiguous_std = data.loc[:, 'z_num_contiguous_values'].std()\n",
    "\n",
    "data.loc[:, 'z_num_contiguous_values'] = data.loc[:, 'z_num_contiguous_values'].\\\n",
    "    transform(lambda x: (x - contiguous_mean) / contiguous_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(data.loc[:, 'z_num_contiguous_values'].mean() - 0)  < 0.0001\n",
    "assert abs(data.loc[:, 'z_num_contiguous_values'].std() - 1) < 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Add feature: value balance between halves of the deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_deck_position_names = []\n",
    "h2_deck_position_names = []\n",
    "\n",
    "for col in value_column_names:\n",
    "    if int(col[4:]) < 26:\n",
    "        h1_deck_position_names.append(col)\n",
    "    else:\n",
    "        h2_deck_position_names.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_deck_positions = data.columns.isin(h1_deck_position_names)\n",
    "h2_deck_positions = data.columns.isin(h2_deck_position_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'z_sum_h1_values'] = data.loc[:, h1_deck_positions].sum(axis=1)\n",
    "data.loc[:, 'z_sum_h2_values'] = data.loc[:, h2_deck_positions].sum(axis=1)\n",
    "\n",
    "data['z_diff_h1_h2_values'] = (data['z_sum_h1_values'] - data['z_sum_h2_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_h1_h2_mean = data['z_diff_h1_h2_values'].mean()\n",
    "diff_h1_h2_std = data['z_diff_h1_h2_values'].std()\n",
    "\n",
    "data.loc[:, 'z_diff_h1_h2_values'] = data.loc[:, 'z_diff_h1_h2_values'].\\\n",
    "    transform(lambda x: (x - diff_h1_h2_mean) / diff_h1_h2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(data.loc[:, 'z_diff_h1_h2_values'].mean() - 0) < 0.0001\n",
    "assert abs(data.loc[:, 'z_diff_h1_h2_values'].std() - 1) < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Add feature: color balance between alternating cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_deck_position_names = []\n",
    "odd_deck_position_names = []\n",
    "\n",
    "for col in list(data.columns):\n",
    "    if col[0:1] == 'x':\n",
    "        if int(col[1:]) % 2 == 0:\n",
    "            odd_deck_position_names.append(col)\n",
    "        else:\n",
    "            even_deck_position_names.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_deck_positions = data.columns.isin(even_deck_position_names)\n",
    "odd_deck_positions = data.columns.isin(odd_deck_position_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'z_sum_evens_indexes'] = data.loc[:, even_deck_positions].sum(axis=1)\n",
    "data.loc[:, 'z_sum_odds_indexes'] = data.loc[:, odd_deck_positions].sum(axis=1)\n",
    "\n",
    "data['z_diff_even_odd_indexes'] = (data['z_sum_evens_indexes'] - data['z_sum_odds_indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_even_odd_mean = data['z_diff_even_odd_indexes'].mean()\n",
    "diff_even_odd_std = data['z_diff_even_odd_indexes'].std()\n",
    "\n",
    "data.loc[:, 'z_diff_even_odd_indexes'] = data.loc[:, 'z_diff_even_odd_indexes'].\\\n",
    "    transform(lambda x: (x - diff_even_odd_mean) / diff_even_odd_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(data.loc[:, 'z_diff_even_odd_indexes'].mean() - 0) < 0.0001\n",
    "assert abs(data.loc[:, 'z_diff_even_odd_indexes'].std() - 1) < 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Add feature: color balance between halves of the deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_deck_position_names = []\n",
    "h2_deck_position_names = []\n",
    "\n",
    "for col in card_column_names:\n",
    "    if int(col[1:]) < 26:\n",
    "        h1_deck_position_names.append(col)\n",
    "    else:\n",
    "        h2_deck_position_names.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_deck_positions = data.columns.isin(h1_deck_position_names)\n",
    "h2_deck_positions = data.columns.isin(h2_deck_position_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'z_sum_h1_indexes'] = data.loc[:, h1_deck_positions].sum(axis=1)\n",
    "data.loc[:, 'z_sum_h2_indexes'] = data.loc[:, h2_deck_positions].sum(axis=1)\n",
    "\n",
    "data['z_diff_h1_h2_indexes'] = (data['z_sum_h1_indexes'] - data['z_sum_h2_indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_h1_h2_mean = data['z_diff_h1_h2_indexes'].mean()\n",
    "diff_h1_h2_std = data['z_diff_h1_h2_indexes'].std()\n",
    "\n",
    "data.loc[:, 'z_diff_h1_h2_indexes'] = data.loc[:, 'z_diff_h1_h2_indexes'].\\\n",
    "    transform(lambda x: (x - diff_h1_h2_mean) / diff_h1_h2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(data.loc[:, 'z_diff_h1_h2_indexes'].mean() - 0) < 0.0001\n",
    "assert abs(data.loc[:, 'z_diff_h1_h2_indexes'].std() - 1) < 0.0001  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 Add feature: color balance from top to bottom continuously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 0\n",
    "first_card_column = card_column_names[0]\n",
    "\n",
    "for row in data.index[:]:\n",
    "    num_rows += 1\n",
    "    current_value = 0\n",
    "    previous_value = 0\n",
    "    this_diff = 0\n",
    "    running_diff = 0\n",
    "    for column in card_column_names:\n",
    "        current_value = data.loc[row, column]\n",
    "        this_diff = previous_value - current_value\n",
    "        if (column != first_card_column):\n",
    "            running_diff += this_diff\n",
    "        previous_value = current_value\n",
    "    data.loc[row, 'z_running_diff_indexes'] = running_diff\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_column_mean = data.loc[:, 'z_running_diff_indexes'].mean()\n",
    "running_column_std = data.loc[:, 'z_running_diff_indexes'].std()\n",
    "\n",
    "data.loc[:, 'z_running_diff_indexes'] = data.loc[:, 'z_running_diff_indexes'].\\\n",
    "    transform(lambda x: (x - running_column_mean) / running_column_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(data.loc[:, 'z_running_diff_indexes'].mean() - 0)  < 0.0001\n",
    "assert abs(data.loc[:, 'z_running_diff_indexes'].std() - 1) < 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Create filter for new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_profile_column_names = \\\n",
    "    ['z_num_contiguous_values', 'z_diff_h1_h2_values', 'z_diff_even_odd_indexes',\\\n",
    "     'z_diff_h1_h2_indexes', 'z_running_diff_indexes']\n",
    "deck_profile_columns = data.columns.isin(deck_profile_column_names)\n",
    "deck_profile_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7 Summarize and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### values columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_column_stats('z_num_contiguous_values',\\\n",
    "                   title_str='Value Balance - contiguous vs chunky',\\\n",
    "                   xlabel_str='Number of contiguous positions (standardized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_column_stats('z_diff_h1_h2_values',\\\n",
    "                   title_str='Value Balance - Top Half vs Bottom Half',\\\n",
    "                   xlabel_str='H1 minus H2 Card Values (standardized)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### index columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_column_stats('z_diff_even_odd_indexes',\\\n",
    "                   title_str='Color Balance - Every other card',\\\n",
    "                   xlabel_str='Even - Odd Deck Indexes (standardized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_column_stats('z_diff_h1_h2_indexes',\\\n",
    "                   title_str='Color Balance - Top Half vs Bottom Half',\\\n",
    "                   xlabel_str='H1 - H2 Deck Indexes (standardized)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_column_stats('z_running_diff_indexes',\\\n",
    "                   title_str='Index Balance - column-wise subtraction method',\\\n",
    "                   xlabel_str='Running Column-Wise Index Diff (standardized)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8 Create input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_deck_profile = np.array(train.loc[:, deck_profile_columns])\n",
    "X_test_deck_profile = np.array(test.loc[:, deck_profile_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly_deck_profile = poly.fit_transform(X_train_deck_profile, y_train)\n",
    "X_test_poly_deck_profile = poly.fit_transform(X_test_deck_profile, y_test)\n",
    "X_train_poly_deck_profile.shape\n",
    "X_test_poly_deck_profile.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.9 Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_deck_profile, y_train, X_test_deck_profile, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_poly_deck_profile, y_train, X_test_poly_deck_profile, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor on 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_deck_profile, y_train_regress, X_test_deck_profile, y_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_poly_deck_profile, y_train_regress, X_test_poly_deck_profile, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal.</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model: Identify Quick Losers\n",
    "\n",
    "Is it possible to at least identify those nearly unplayable decks which lose after a short number of moves?\n",
    "\n",
    "Perhaps a user would find value in avoiding decks which don't justify the time it takes to shuffle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Find minimum move threshold for a 'fun' deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.hist(data.loc[data.won==0].num_moves,bins=50, label='lost')\n",
    "_=plt.hist(data.loc[data.won==1].num_moves,bins=50, label='won')\n",
    "_=plt.axvline(x=14, color='red', linewidth=.8, linestyle='--')\n",
    "_=plt.xlabel('# moves')\n",
    "_=plt.legend()\n",
    "_=plt.title('Histogram num_moves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.num_moves<14, 'fun'] = 0\n",
    "data.loc[data.num_moves>=14, 'fun'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Create input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_fun = np.array(train.loc[:,(train.columns=='fun')].iloc[:,0])\n",
    "y_test_fun = np.array(test.loc[:,(test.columns=='fun')].iloc[:,0])\n",
    "\n",
    "y_train_fun.shape, y_test_fun.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New baseline (fun == 1 in the test set): {}'.format(len(test.loc[test.fun==1])/len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train, y_train_fun, X_test, y_test_fun, baseline=.9356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_deck_profile, y_train_fun, X_test_deck_profile, y_test_fun, baseline=.9356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_important_column_features,y_train_fun,X_test_important_column_features,\\\n",
    "                     y_test_fun,baseline=.9356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal.</span></b>\n",
    "No 'fun' generalization found for these sets of training data. Model always predicts 'fun'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model: Gut Check\n",
    "\n",
    "Add a noisy explanatory column to see if models can properly classify won/lost when at least one column has predictive ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Degrade num_moves feature with random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noisy_explanatory = True\n",
    "\n",
    "if add_noisy_explanatory:\n",
    "    import random\n",
    "    random.seed(0)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        \n",
    "        # ensure num_moves is not already modified by re-importing raw values saved earlier\n",
    "        train.loc[:,'num_moves'] = y_train_regress\n",
    "        test.loc[:,'num_moves'] = y_test_regress\n",
    "        \n",
    "        # randomly modify 'num_moves' in the training & testing sets.\n",
    "        train_sample_row_indexes = train.num_moves.sample(len(train.num_moves)//1).index\n",
    "        test_sample_row_indexes = test.num_moves.sample(len(test.num_moves)//1).index\n",
    "        \n",
    "        train.loc[train_sample_row_indexes, 'num_moves'] = train.loc[train_sample_row_indexes, 'num_moves'].\\\n",
    "            transform(lambda x: x*(random.choice(np.linspace(.85,1.15,num=5))))\n",
    "        test.loc[test_sample_row_indexes, 'num_moves'] = test.loc[test_sample_row_indexes, 'num_moves'].\\\n",
    "            transform(lambda x: x*(random.choice(np.linspace(.85,1.15,num=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Create input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_dummies_gut_check = \\\n",
    "    np.array(train.loc[:, (train.columns.isin(card_column_names))|(train.columns == 'num_moves')])\n",
    "X_test_with_dummies_gut_check = \\\n",
    "    np.array(test.loc[:, (test.columns.isin(card_column_names))|(test.columns == 'num_moves')])\n",
    "\n",
    "X_train_with_dummies_gut_check.shape\n",
    "X_test_with_dummies_gut_check.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 Run models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_and_chart(X_train_with_dummies_gut_check, y_train, X_test_with_dummies_gut_check, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostRegressor on 'num_moves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_and_chart(X_train_with_dummies_gut_check, y_train_regress, X_test_with_dummies_gut_check, y_test_regress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:lightseagreen; font-size:14pt\">Signal found.</span></b>\n",
    "\n",
    "The deep model has no problem predicting won/lost when a degraded num_moves field is added to the original 52 card index columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions\n",
    "\n",
    "See top of notebook for complete summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color:indian red; font-size:14pt\">No signal found.</span></b>\n",
    "\n",
    "It appears winning decks are unique and win through sufficiently complex processes (minimum 115 moves) that their initial states are indistiguishable.\n",
    "\n",
    "Winners and Losers seem to be determined by minute and critical differences in the ordering of a single card or two.\n",
    "\n",
    "My personal experience agrees in that I often find a WIN comes down to a single 'linchpin' card that either breaks a lockjam or fails to appear when I need it. This deck would look statistically indistiguishable from a deck where that linchpin card is offset by a single card.\n",
    "\n",
    "As a fallback, I tried to identify just unplayable decks (those which lose after a small number of moves), but also found no signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
